// Copyright 2019 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#version 460

//
// RASTERS ALLOC
//

#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_ballot : require

//
//
//

#include "spn_config.h"
#include "spn_vk_layouts.h"

//
//
//

layout(local_size_x = SPN_KERNEL_RASTERS_ALLOC_WORKGROUP_SIZE) in;

//
//
//

SPN_VK_GLSL_DECL_KERNEL_RASTERS_ALLOC();

//
// There is a fixed-size meta table per raster cohort that we use to
// peform a mostly coalesced sizing and allocation of blocks.
//
// This code is simple and fast.
//

void
main()
{
  // access to the meta extent is linear
  const bool is_active = gl_GlobalInvocationID.x < raster_span;

  // raster index
  uint raster_idx = raster_head + gl_GlobalInvocationID.x;

  if (raster_idx >= raster_size)
    {
      raster_idx -= raster_size;
    }

  //
  // we don't actually use the alloc.rkoff value
  //
  uvec4 alloc;

  alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_RKOFF] =
    ttrks_meta.alloc[gl_GlobalInvocationID.x][SPN_RASTER_COHORT_META_ALLOC_OFFSET_RKOFF];

  //
  // active cohorts store the computed info directly to the header block
  //
  uint  raster_h;
  uvec4 rh_0123;
  uint  ttsks;
  uint  extra = 0;

  if (is_active)
    {
      // load raster_id as early as possible
      raster_h = raster_ids[raster_idx];

      // load meta_in
      rh_0123[SPN_RASTER_HEAD_LO_OFFSET_BLOCKS] = ttrks_meta.blocks[gl_GlobalInvocationID.x];
      rh_0123[SPN_RASTER_HEAD_LO_OFFSET_TTPKS]  = ttrks_meta.ttpks[gl_GlobalInvocationID.x];
      ttsks                                     = ttrks_meta.ttrks[gl_GlobalInvocationID.x];

      // how many blocks will the ttpb vectors consume?
      extra = (rh_0123[SPN_RASTER_HEAD_LO_OFFSET_TTPKS] + SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK - 1) /
              SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK;

      // total keys
      const uint ttxks = rh_0123[SPN_RASTER_HEAD_LO_OFFSET_TTPKS] + ttsks;

      //
      // how many extra blocks do we need to store all the keys in a
      // head and nodes?
      //
      // note: the "-1" is due to the final qword being used to point to
      // the next node
      //
      const uint ttxks_hn_pad = SPN_RASTER_HEAD_QWORDS + ttxks;
      const uint ttxks_hn_ru  = ttxks_hn_pad + SPN_RASTER_NODE_QWORDS - 2;
      const uint ttxks_hn     = ttxks_hn_ru / (SPN_RASTER_NODE_QWORDS - 1);

      // increment blocks
      extra += ttxks_hn;

      // update blocks
      rh_0123[SPN_RASTER_HEAD_LO_OFFSET_BLOCKS] += extra;

      // how many nodes trail the head?
      rh_0123[SPN_RASTER_HEAD_LO_OFFSET_NODES] = ttxks_hn - 1;
    }

  //
  // allocate blocks from block pool
  //
  // first perform a prefix sum on the subgroup to reduce atomic
  // operation traffic
  //
  // note this idiom can be pushed further to operate across a workgroup
  // or operated on vectors.
  //
  const uint inc         = subgroupInclusiveAdd(extra);
  uint       bp_ids_base = 0;

  // last lane performs the block pool alloc with an atomic increment
  if (gl_SubgroupInvocationID == SPN_KERNEL_RASTERS_ALLOC_SUBGROUP_SIZE - 1)
    {
      bp_ids_base = atomicAdd(bp_atomics[0], inc);
    }

  // broadcast block pool base to all lanes
  bp_ids_base = subgroupBroadcast(bp_ids_base, SPN_KERNEL_RASTERS_ALLOC_SUBGROUP_SIZE - 1);

  //
  // store meta header
  //
  if (is_active)
    {
      // exclusive
      const uint exc = inc - extra;

      // update block pool reads base for each lane
      const uint reads = bp_ids_base + exc;

      // get block_id of each raster head
      const uint head_block_id = bp_ids[reads & bp_mask];

      // update map
      bp_host_map[raster_h] = head_block_id;

      //
      // The layout of allocated blocks is as follows:
      //
      //   ... | HEAD(1) | NODES(0+) | TTPB(0+) | ...
      //
      // Unlike previous Spinel implementations, TTPK keys immediately
      // follow TTSK keys.  The starting index of the TTPK keys in the
      // head or nodes is recorded in the raster header.
      //
      const uint pk_hn_pad = SPN_RASTER_HEAD_QWORDS + ttsks;
      const uint pk_hn_idx = pk_hn_pad / (SPN_RASTER_NODE_QWORDS - 1);
      const uint pk_hn_rd  = pk_hn_idx * (SPN_RASTER_NODE_QWORDS - 1);
      const uint pk_hn_off = pk_hn_pad - pk_hn_rd;

      const uint pkidx_reads      = reads + pk_hn_idx;
      const uint pkidx_block_id   = bp_ids[pkidx_reads & bp_mask];
      const uint pkidx_dword_base = pkidx_block_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS;

      // absolute block pool index of starting TTPK key in raster
      rh_0123[SPN_RASTER_HEAD_LO_OFFSET_PKIDX] = pkidx_dword_base + pk_hn_off;

      // store ttrk and ttpk block reads in meta table
      alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_READS]  = reads;
      alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_PKNODE] = pkidx_reads;

      ttrks_meta.alloc[gl_GlobalInvocationID.x] = alloc;

      //
      // write out uvec4 and uvec2 to header
      //
      // resulting in this:
      //
      //   raster head block
      //   {
      //     struct spn_raster_header.lo
      //     {
      //       uint32_t blocks;  // # of blocks -- head+node+skb+pkb
      //       uint32_t nodes;   // # of nodes  -- not including header
      //       uint32_t pkidx;   // absolute block pool qword of ttpk span
      //       uint32_t ttpks;   // # of ttpks
      //       uint32_t ttsks;   // # of ttsks
      //
      //       ... uninitialized ...
      //     }
      //     ...
      //   }
      //
      // NOTE(allanmac): We're explicitly writing a second uvec4 because
      // GLSL appears to be confused by the block pool descriptor
      // aliasing (which is technically illegal).  It's likely a
      // spirv-opt or glslangValidator error.  Once buffer references
      // are available, we can write this the correct way.
      //
      bp_blocks_uvec4[head_block_id * SPN_BLOCK_POOL_SUBBLOCK_OWORDS + 0] = rh_0123;
      bp_blocks_uvec4[head_block_id * SPN_BLOCK_POOL_SUBBLOCK_OWORDS + 1] = uvec4(ttsks, 0, 0, 0);

      //
      // DEBUG
      //
#if 0
      {
        const uint debug_base =
          atomicAdd(bp_debug_count[0], SPN_KERNEL_RASTERS_ALLOC_SUBGROUP_SIZE);

        bp_debug[debug_base + 0] = raster_idx;
        bp_debug[debug_base + 1] = rh_0123[0];
        bp_debug[debug_base + 2] = rh_0123[1];
        bp_debug[debug_base + 3] = rh_0123[2];
        bp_debug[debug_base + 4] = rh_0123[3];
        bp_debug[debug_base + 5] = ttsks;
        bp_debug[debug_base + 6] = alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_RKOFF];
        bp_debug[debug_base + 7] = alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_READS];
        bp_debug[debug_base + 8] = alloc[SPN_RASTER_COHORT_META_ALLOC_OFFSET_PKNODE];
      }
#endif
    }
}

//
//
//
